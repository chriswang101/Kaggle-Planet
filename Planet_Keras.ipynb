{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tqdm\n",
    "\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_filepath = \"../../../../../../Volumes/Seagate Backup Plus Drive/Documents/Kaggle Datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(pre_filepath + \"Planet/train_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "labels = list(set(flatten([l.split(' ') for l in df_train['tags'].values])))\n",
    "\n",
    "label_map = {l: i for i, l in enumerate(labels)}\n",
    "inv_label_map = {i: l for l, i in label_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blow_down',\n",
       " 'bare_ground',\n",
       " 'artisinal_mine',\n",
       " 'haze',\n",
       " 'conventional_mine',\n",
       " 'water',\n",
       " 'partly_cloudy',\n",
       " 'clear',\n",
       " 'habitation',\n",
       " 'primary',\n",
       " 'cultivation',\n",
       " 'road',\n",
       " 'slash_burn',\n",
       " 'selective_logging',\n",
       " 'agriculture',\n",
       " 'blooming',\n",
       " 'cloudy']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_map = {i : j for i, j in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'blow_down',\n",
       " 1: 'bare_ground',\n",
       " 2: 'artisinal_mine',\n",
       " 3: 'haze',\n",
       " 4: 'conventional_mine',\n",
       " 5: 'water',\n",
       " 6: 'partly_cloudy',\n",
       " 7: 'clear',\n",
       " 8: 'habitation',\n",
       " 9: 'primary',\n",
       " 10: 'cultivation',\n",
       " 11: 'road',\n",
       " 12: 'slash_burn',\n",
       " 13: 'selective_logging',\n",
       " 14: 'agriculture',\n",
       " 15: 'blooming',\n",
       " 16: 'cloudy'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {j : i for i, j in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agriculture': 14,\n",
       " 'artisinal_mine': 2,\n",
       " 'bare_ground': 1,\n",
       " 'blooming': 15,\n",
       " 'blow_down': 0,\n",
       " 'clear': 7,\n",
       " 'cloudy': 16,\n",
       " 'conventional_mine': 4,\n",
       " 'cultivation': 10,\n",
       " 'habitation': 8,\n",
       " 'haze': 3,\n",
       " 'partly_cloudy': 6,\n",
       " 'primary': 9,\n",
       " 'road': 11,\n",
       " 'selective_logging': 13,\n",
       " 'slash_burn': 12,\n",
       " 'water': 5}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [32:41<00:00, 20.64it/s]\n"
     ]
    }
   ],
   "source": [
    "for file_name, tags in tqdm.tqdm(df_train.values, miniters=100):\n",
    "    \n",
    "    image = cv2.imread(pre_filepath + \"Planet/train-tif-v2/\" + file_name + \".tif\")\n",
    "    targets = np.zeros(17)\n",
    "    for tag in tags.split(' '):\n",
    "        targets[label_map[tag]] = 1\n",
    "    X_train.append(cv2.resize(image, (64, 64)))\n",
    "    y_train.append(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, np.float16) / 255\n",
    "y_train = np.array(y_train, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40481, 64, 64, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40481, 17)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 35000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = X_train[:validation_split], X_train[validation_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = y_train[:validation_split], y_train[validation_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35000 samples, validate on 5481 samples\n",
      "Epoch 1/4\n",
      "35000/35000 [==============================] - 353s - loss: 0.2528 - acc: 0.9033 - val_loss: 0.4621 - val_acc: 0.8960\n",
      "Epoch 2/4\n",
      "35000/35000 [==============================] - 346s - loss: 0.2335 - acc: 0.9082 - val_loss: 0.2997 - val_acc: 0.8925\n",
      "Epoch 3/4\n",
      "35000/35000 [==============================] - 345s - loss: 0.2239 - acc: 0.9130 - val_loss: 0.2519 - val_acc: 0.9072\n",
      "Epoch 4/4\n",
      "35000/35000 [==============================] - 344s - loss: 0.2182 - acc: 0.9145 - val_loss: 0.2335 - val_acc: 0.9128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120ede940>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making the Keras model\n",
    "model = Sequential()\n",
    "\n",
    "# First conv layer\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "# Second conv layer\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "# Flatten before FC layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Third FC layer\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "# Final FC layer to output\n",
    "model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size = 128, epochs=4, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 1 0 0]\n",
      " [0 0 0 ..., 1 0 0]]\n",
      "[[ 0.01141668  0.0324084   0.01230208 ...,  0.37550899  0.02821972\n",
      "   0.0115757 ]\n",
      " [ 0.00633154  0.04981474  0.01279089 ...,  0.53140497  0.01163766\n",
      "   0.09105454]\n",
      " [ 0.00636821  0.01809446  0.00608225 ...,  0.30736524  0.01875447\n",
      "   0.00509066]\n",
      " ..., \n",
      " [ 0.0041061   0.12024331  0.04095884 ...,  0.67764372  0.00425965\n",
      "   0.13108748]\n",
      " [ 0.00361769  0.10869204  0.03326196 ...,  0.68432719  0.00375857\n",
      "   0.12586874]\n",
      " [ 0.01118554  0.04454163  0.0158408  ...,  0.48249     0.02261144\n",
      "   0.02048526]]\n",
      "0.742743734914\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model \n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "p_valid = model.predict(X_valid, batch_size=128)\n",
    "print(y_valid)\n",
    "print(p_valid)\n",
    "print(fbeta_score(y_valid, np.array(p_valid) > 0.2, beta=2, average='samples'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
